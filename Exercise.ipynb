{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- EXERCISE -------------------------\n",
    "# Use whole data 500000\n",
    "#\n",
    "\n",
    "x_data = np.linspace(0.0,10.0,500000) # Create Data\n",
    "print('X Data', x_data)\n",
    "noise = np.random.randn(len(x_data))\n",
    "#print('Noise: ',noise)\n",
    "\n",
    "y_data = (0.5*x_data) + 5 + noise\n",
    "print('Y Data', y_data)\n",
    "\n",
    "# To form table or column data.... \n",
    "data_frame = pd.concat([pd.DataFrame(data=x_data,columns=['X Data']), pd.DataFrame(data=y_data,columns=['Y Data'])],axis=1)\n",
    "print(data_frame.head(10))\n",
    "\n",
    "data_frame.sample(n=250).plot(kind='scatter', x='X Data', y='Y Data')\n",
    "plt.show(); plt.close();\n",
    "\n",
    "# Define Model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(units=1, input_dim=1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mse'] )\n",
    "\n",
    "model.summary() # Number of Trainable Params = output_size * (input_size+1)\n",
    "\n",
    "# ------------------------------- Code Block #2 --------------------------------\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./keras')        # Batch size can vary from (1 to thousands of #)\n",
    "                                                    # Also there is a relation between epochs and batch_size \n",
    "hist = model.fit(x=x_data[0:500000], y=y_data[0:500000], batch_size=1000, epochs=20, shuffle=True, callbacks=[tensorboard])\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Defining Saver Object to Save Graph After Executing Within Session \n",
    "\n",
    "number_of_epochs = 20      # same as used above \n",
    "training_loss = hist.history['loss']\n",
    "x = range(number_of_epochs)\n",
    "\n",
    "plt.plot(x, training_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.savefig('Plot.png')\n",
    "plt.close()\n",
    "\n",
    "print('Number of Layers :', len(model.layers))\n",
    "model_parameters = model.layers[0].get_weights()\n",
    "w=model_parameters[0][0]\n",
    "b=model_parameters[1]\n",
    "print('Model Gradient (W) :', model_parameters[0][0]) \n",
    "print('Model Intercept (b) :', model_parameters[1])\n",
    "\n",
    "\n",
    "\n",
    "# To draw linear regression line, we have to use y = wx+b equation using weight and b=intercept/bias as well\n",
    "\n",
    "x=[0,1,2,3,4,5,6,7,8,9,10]\n",
    "y = w*x + b\n",
    "data_frame.sample(n=250).plot(kind='scatter', x='X Data', y='Y Data')\n",
    "#plt.plot(x_data, model,'r')\n",
    "plt.plot(x,y, 'r')\n",
    "plt.savefig('Plot_1.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
